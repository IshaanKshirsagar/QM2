{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_18712\\3906387663.py:5: DtypeWarning: Columns (7,23,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk_1 = pd.read_csv('./chunks/aug_chunk_1.csv')\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/sinking8/usc-x-24-us-election.git\n",
    "\n",
    "#Part 1:\n",
    "\n",
    "chunk_1 = pd.read_csv('./chunks/aug_chunk_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>epoch</th>\n",
       "      <th>media</th>\n",
       "      <th>retweetedTweet</th>\n",
       "      <th>retweetedTweetID</th>\n",
       "      <th>retweetedUserID</th>\n",
       "      <th>...</th>\n",
       "      <th>links</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>location</th>\n",
       "      <th>cash_app_handle</th>\n",
       "      <th>user</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet-</td>\n",
       "      <td>1.842096e+18</td>\n",
       "      <td>Debbie133467421</td>\n",
       "      <td>Kamala Harris is very connected to Diddy. She ...</td>\n",
       "      <td>https://twitter.com/Debbie133467421/status/184...</td>\n",
       "      <td>1.728025e+09</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'display_url': 'youtube.com/shorts/WTYBwdp‚Ä¶'...</td>\n",
       "      <td>{'state': 'Enabled'}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': 1820716370360975360, 'id_str': '1820716...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweet-</td>\n",
       "      <td>1.842096e+18</td>\n",
       "      <td>EMGENT_007</td>\n",
       "      <td>@iamnot_elon 100% Sir!</td>\n",
       "      <td>https://twitter.com/EMGENT_007/status/18420955...</td>\n",
       "      <td>1.728025e+09</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'state': 'Enabled'}</td>\n",
       "      <td>False</td>\n",
       "      <td>iamnot_elon</td>\n",
       "      <td>1.842041e+18</td>\n",
       "      <td>1.652734e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': 1772432144033521664, 'id_str': '1772432...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tweet-</td>\n",
       "      <td>1.842096e+18</td>\n",
       "      <td>wellyworldfl</td>\n",
       "      <td>@catturd2 And all the insurance companies will...</td>\n",
       "      <td>https://twitter.com/wellyworldfl/status/184209...</td>\n",
       "      <td>1.728025e+09</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'state': 'Enabled'}</td>\n",
       "      <td>False</td>\n",
       "      <td>catturd2</td>\n",
       "      <td>1.841787e+18</td>\n",
       "      <td>1.043186e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': 156726345, 'id_str': '156726345', 'url'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tweet-</td>\n",
       "      <td>1.842096e+18</td>\n",
       "      <td>emi79907</td>\n",
       "      <td>@CatholicQuote12 BEAUTIFUL üôèüôèüôèüôè</td>\n",
       "      <td>https://twitter.com/emi79907/status/1842095589...</td>\n",
       "      <td>1.728025e+09</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'state': 'Enabled'}</td>\n",
       "      <td>False</td>\n",
       "      <td>CatholicQuote12</td>\n",
       "      <td>1.841753e+18</td>\n",
       "      <td>1.794233e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': 1765294849471676416, 'id_str': '1765294...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tweet-</td>\n",
       "      <td>1.842096e+18</td>\n",
       "      <td>hope_neverLost1</td>\n",
       "      <td>9 Jahre Haft. #TinaPeters hatte ein privilegie...</td>\n",
       "      <td>https://twitter.com/hope_neverLost1/status/184...</td>\n",
       "      <td>1.728025e+09</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'state': 'Enabled'}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': 52490268, 'id_str': '52490268', 'url': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type            id         username  \\\n",
       "0  tweet-  1.842096e+18  Debbie133467421   \n",
       "1  tweet-  1.842096e+18       EMGENT_007   \n",
       "2  tweet-  1.842096e+18     wellyworldfl   \n",
       "3  tweet-  1.842096e+18         emi79907   \n",
       "4  tweet-  1.842096e+18  hope_neverLost1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Kamala Harris is very connected to Diddy. She ...   \n",
       "1                             @iamnot_elon 100% Sir!   \n",
       "2  @catturd2 And all the insurance companies will...   \n",
       "3                    @CatholicQuote12 BEAUTIFUL üôèüôèüôèüôè   \n",
       "4  9 Jahre Haft. #TinaPeters hatte ein privilegie...   \n",
       "\n",
       "                                                 url         epoch media  \\\n",
       "0  https://twitter.com/Debbie133467421/status/184...  1.728025e+09    []   \n",
       "1  https://twitter.com/EMGENT_007/status/18420955...  1.728025e+09    []   \n",
       "2  https://twitter.com/wellyworldfl/status/184209...  1.728025e+09    []   \n",
       "3  https://twitter.com/emi79907/status/1842095589...  1.728025e+09    []   \n",
       "4  https://twitter.com/hope_neverLost1/status/184...  1.728025e+09    []   \n",
       "\n",
       "  retweetedTweet  retweetedTweetID  retweetedUserID  ...  \\\n",
       "0          False               NaN              NaN  ...   \n",
       "1          False               NaN              NaN  ...   \n",
       "2          False               NaN              NaN  ...   \n",
       "3          False               NaN              NaN  ...   \n",
       "4          False               NaN              NaN  ...   \n",
       "\n",
       "                                               links             viewCount  \\\n",
       "0  [{'display_url': 'youtube.com/shorts/WTYBwdp‚Ä¶'...  {'state': 'Enabled'}   \n",
       "1                                                 []  {'state': 'Enabled'}   \n",
       "2                                                 []  {'state': 'Enabled'}   \n",
       "3                                                 []  {'state': 'Enabled'}   \n",
       "4                                                 []  {'state': 'Enabled'}   \n",
       "\n",
       "  quotedTweet  in_reply_to_screen_name  in_reply_to_status_id_str  \\\n",
       "0       False                      NaN                        NaN   \n",
       "1       False              iamnot_elon               1.842041e+18   \n",
       "2       False                 catturd2               1.841787e+18   \n",
       "3       False          CatholicQuote12               1.841753e+18   \n",
       "4        True                      NaN                        NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  location  cash_app_handle  \\\n",
       "0                      NaN       NaN              NaN   \n",
       "1             1.652734e+18       NaN              NaN   \n",
       "2             1.043186e+18       NaN              NaN   \n",
       "3             1.794233e+18       NaN              NaN   \n",
       "4                      NaN       NaN              NaN   \n",
       "\n",
       "                                                user    0  \n",
       "0  {'id': 1820716370360975360, 'id_str': '1820716...  NaN  \n",
       "1  {'id': 1772432144033521664, 'id_str': '1772432...  NaN  \n",
       "2  {'id': 156726345, 'id_str': '156726345', 'url'...  NaN  \n",
       "3  {'id': 1765294849471676416, 'id_str': '1765294...  NaN  \n",
       "4  {'id': 52490268, 'id_str': '52490268', 'url': ...  NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important columns: 'text', 'user', \n",
    "columns = ['text', 'user']\n",
    "\n",
    "chunk = chunk_1[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamala Harris is very connected to Diddy. She ...</td>\n",
       "      <td>{'id': 1820716370360975360, 'id_str': '1820716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@iamnot_elon 100% Sir!</td>\n",
       "      <td>{'id': 1772432144033521664, 'id_str': '1772432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@catturd2 And all the insurance companies will...</td>\n",
       "      <td>{'id': 156726345, 'id_str': '156726345', 'url'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CatholicQuote12 BEAUTIFUL üôèüôèüôèüôè</td>\n",
       "      <td>{'id': 1765294849471676416, 'id_str': '1765294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9 Jahre Haft. #TinaPeters hatte ein privilegie...</td>\n",
       "      <td>{'id': 52490268, 'id_str': '52490268', 'url': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Kamala Harris is very connected to Diddy. She ...   \n",
       "1                             @iamnot_elon 100% Sir!   \n",
       "2  @catturd2 And all the insurance companies will...   \n",
       "3                    @CatholicQuote12 BEAUTIFUL üôèüôèüôèüôè   \n",
       "4  9 Jahre Haft. #TinaPeters hatte ein privilegie...   \n",
       "\n",
       "                                                user  \n",
       "0  {'id': 1820716370360975360, 'id_str': '1820716...  \n",
       "1  {'id': 1772432144033521664, 'id_str': '1772432...  \n",
       "2  {'id': 156726345, 'id_str': '156726345', 'url'...  \n",
       "3  {'id': 1765294849471676416, 'id_str': '1765294...  \n",
       "4  {'id': 52490268, 'id_str': '52490268', 'url': ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change text column to string\n",
    "#A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "chunk.loc[:,'text'] = chunk['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_copy = chunk.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sofia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sofia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\sofia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sofia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Additional common words to ignore can be added to the stop words\n",
    "additional_stopwords = {'http', 'https', 'co', 'com', 'rt', 'biden', 'trump', 'maga', 'joe', 'gop', 'bidens', 'president', 'kamala', 'harris', 'kamala harris', 'democrat', 'democratic', 'democrats', 'donald', 'republican', 'former' }\n",
    "stop_words.update(additional_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and tokenize text\n",
    "def clean_tokenize(text):\n",
    "   # Remove URLs, hashtags, mentions, special characters, and numbers\n",
    "   text = re.sub(r\"(http\\S+)|(#\\S+)|(@\\S+)|[^a-zA-Z\\s]|(\\w*\\d\\w*)\", '', text)\n",
    "   # Convert to lower case\n",
    "   text = text.lower()\n",
    "   # Tokenize the text\n",
    "   words = text.split()\n",
    "   # Remove stop words\n",
    "   words = [word for word in words if word not in stop_words]\n",
    "   return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(df):\n",
    "   df['cleaned_text'] = df['text'].apply(clean_tokenize)\n",
    "   # Flatten the list of words in all tweets into a single list\n",
    "   all_words = [word for words_list in df['cleaned_text'] for word in words_list]\n",
    "   # Count the occurrences of each word\n",
    "   word_counts = Counter(all_words)\n",
    "   # Get the most common words\n",
    "   most_common_words = word_counts.most_common(100)  # Adjust the number as needed\n",
    "   # Display the most common words\n",
    "   for i in range(len(most_common_words)):\n",
    "       print(f'{most_common_words[i][0]}: {most_common_words[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to clean, tokenize, and filter adjectives\n",
    "def clean_tokenize2(text):\n",
    "   # Remove URLs, hashtags, mentions, special characters, and numbers\n",
    "   text = re.sub(r\"(http\\S+)|(#\\S+)|(@\\S+)|[^a-zA-Z\\s]|(\\w*\\d\\w*)\", '', text)\n",
    "   # Convert to lower case\n",
    "   text = text.lower()\n",
    "   # Tokenize the text\n",
    "   words = nltk.word_tokenize(text)\n",
    "   # Part-of-speech tagging\n",
    "   pos_tags = nltk.pos_tag(words)\n",
    "   # Filter adjectives, identified by 'JJ' tag\n",
    "   adjectives = [word for word, tag in pos_tags if tag.startswith('JJ') and word not in stop_words]\n",
    "   return adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_adjectives(df):\n",
    "   # Apply the cleaning and tokenization function to each tweet\n",
    "    df['adjectives'] = df['text'].apply(clean_tokenize2)\n",
    "    # Flatten the list of adjectives in all tweets into a single list\n",
    "    all_adjectives = [adj for adj_list in df['adjectives'] for adj in adj_list]\n",
    "    # Count the occurrences of each adjective\n",
    "    adjective_counts = Counter(all_adjectives)\n",
    "    # Get the most common adjectives\n",
    "    most_common_adjectives = adjective_counts.most_common(30)  # Adjust the number as needed\n",
    "    # Display the most common adjectives\n",
    "    for i in range(len(most_common_adjectives)):\n",
    "        print(f'{most_common_adjectives[i][0]}: {most_common_adjectives[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['Donald Trump', 'Trump', 'MAGA']\n",
    "# Filter the DataFrame to include only tweets containing any of the keywords\n",
    "# The 'na=False' parameter ensures that tweets with 'NaN' text are ignored\n",
    "filtered_df = chunk_copy[chunk_copy['text'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "keywords2 = ['Kamala Harris', 'harris', 'kamala', 'democrat', 'democratic']\t\n",
    "filtered_df2 = chunk_copy[chunk_copy['text'].str.contains('|'.join(keywords2), case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in tweets about Trump:\n",
      "like: 1818\n",
      "people: 1631\n",
      "amp: 1418\n",
      "dont: 1380\n",
      "vote: 1190\n",
      "trumps: 1135\n",
      "one: 1075\n",
      "get: 1065\n",
      "would: 1035\n",
      "know: 974\n",
      "im: 847\n",
      "us: 829\n",
      "think: 827\n",
      "going: 814\n",
      "hes: 800\n",
      "never: 715\n",
      "time: 697\n",
      "right: 694\n",
      "election: 691\n",
      "party: 673\n",
      "america: 666\n",
      "thats: 661\n",
      "see: 658\n",
      "want: 655\n",
      "even: 651\n",
      "youre: 650\n",
      "make: 629\n",
      "years: 623\n",
      "back: 623\n",
      "said: 617\n",
      "need: 592\n",
      "country: 587\n",
      "cant: 572\n",
      "go: 571\n",
      "doesnt: 558\n",
      "way: 552\n",
      "cult: 540\n",
      "lies: 540\n",
      "good: 520\n",
      "say: 492\n",
      "didnt: 490\n",
      "republicans: 478\n",
      "voting: 476\n",
      "de: 467\n",
      "still: 461\n",
      "really: 457\n",
      "campaign: 451\n",
      "stop: 440\n",
      "also: 434\n",
      "win: 432\n",
      "got: 432\n",
      "well: 430\n",
      "many: 428\n",
      "better: 426\n",
      "believe: 424\n",
      "much: 419\n",
      "every: 416\n",
      "nothing: 410\n",
      "take: 407\n",
      "rally: 393\n",
      "support: 390\n",
      "man: 388\n",
      "old: 382\n",
      "could: 380\n",
      "great: 374\n",
      "plane: 372\n",
      "love: 367\n",
      "yes: 362\n",
      "isnt: 357\n",
      "another: 354\n",
      "money: 351\n",
      "anything: 350\n",
      "look: 349\n",
      "thing: 348\n",
      "hate: 345\n",
      "conservative: 345\n",
      "new: 344\n",
      "real: 341\n",
      "media: 340\n",
      "news: 337\n",
      "day: 337\n",
      "debate: 330\n",
      "world: 328\n",
      "ever: 321\n",
      "always: 319\n",
      "theyre: 319\n",
      "sure: 314\n",
      "keep: 313\n",
      "border: 312\n",
      "done: 312\n",
      "last: 309\n",
      "says: 306\n",
      "left: 306\n",
      "american: 305\n",
      "first: 304\n",
      "needs: 302\n",
      "voters: 300\n",
      "wont: 299\n",
      "since: 299\n",
      "montana: 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_18712\\3891492744.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_text'] = df['text'].apply(clean_tokenize)\n"
     ]
    }
   ],
   "source": [
    "print('Most common words in tweets about Trump:')\n",
    "common_words(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common adjectives in tweets about Trump:\n",
      "good: 509\n",
      "many: 428\n",
      "old: 382\n",
      "great: 374\n",
      "conservative: 345\n",
      "new: 344\n",
      "real: 341\n",
      "last: 309\n",
      "american: 305\n",
      "white: 295\n",
      "much: 290\n",
      "better: 280\n",
      "bad: 279\n",
      "right: 259\n",
      "sure: 249\n",
      "amp: 242\n",
      "true: 227\n",
      "black: 216\n",
      "big: 208\n",
      "first: 203\n",
      "wrong: 200\n",
      "im: 192\n",
      "dont: 187\n",
      "free: 185\n",
      "best: 179\n",
      "trumps: 178\n",
      "political: 175\n",
      "mechanical: 170\n",
      "next: 163\n",
      "stupid: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_18712\\2122204458.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['adjectives'] = df['text'].apply(clean_tokenize2)\n"
     ]
    }
   ],
   "source": [
    "print('\\nMost common adjectives in tweets about Trump:')\n",
    "common_adjectives(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common words in tweets about Kamala Harris:\n",
      "people: 1029\n",
      "vote: 962\n",
      "like: 933\n",
      "amp: 913\n",
      "party: 891\n",
      "bidenharris: 690\n",
      "dont: 676\n",
      "us: 614\n",
      "one: 605\n",
      "would: 591\n",
      "get: 559\n",
      "america: 507\n",
      "years: 490\n",
      "know: 486\n",
      "going: 457\n",
      "support: 450\n",
      "country: 442\n",
      "think: 434\n",
      "border: 426\n",
      "even: 413\n",
      "election: 408\n",
      "want: 404\n",
      "administration: 404\n",
      "im: 392\n",
      "campaign: 382\n",
      "thats: 360\n",
      "time: 352\n",
      "cant: 351\n",
      "never: 346\n",
      "right: 338\n",
      "said: 338\n",
      "american: 337\n",
      "walz: 330\n",
      "voting: 328\n",
      "see: 326\n",
      "back: 306\n",
      "hes: 302\n",
      "americans: 298\n",
      "shes: 296\n",
      "media: 296\n",
      "go: 291\n",
      "make: 291\n",
      "doesnt: 287\n",
      "policies: 287\n",
      "republicans: 286\n",
      "win: 284\n",
      "need: 283\n",
      "vp: 282\n",
      "youre: 281\n",
      "nothing: 274\n",
      "still: 273\n",
      "many: 271\n",
      "really: 270\n",
      "way: 266\n",
      "voters: 266\n",
      "illegal: 256\n",
      "say: 253\n",
      "debate: 253\n",
      "done: 251\n",
      "money: 250\n",
      "didnt: 249\n",
      "new: 244\n",
      "states: 240\n",
      "well: 240\n",
      "good: 238\n",
      "trumps: 236\n",
      "also: 232\n",
      "got: 230\n",
      "much: 230\n",
      "via: 226\n",
      "candidate: 225\n",
      "better: 223\n",
      "care: 222\n",
      "stop: 222\n",
      "left: 218\n",
      "take: 214\n",
      "every: 214\n",
      "since: 213\n",
      "last: 210\n",
      "obama: 210\n",
      "wont: 209\n",
      "could: 208\n",
      "conservative: 203\n",
      "lies: 203\n",
      "believe: 200\n",
      "illegals: 199\n",
      "running: 198\n",
      "state: 194\n",
      "everything: 193\n",
      "world: 192\n",
      "isnt: 190\n",
      "keep: 190\n",
      "de: 188\n",
      "thing: 188\n",
      "cheney: 186\n",
      "first: 186\n",
      "dems: 184\n",
      "hate: 182\n",
      "help: 181\n",
      "day: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_18712\\3891492744.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_text'] = df['text'].apply(clean_tokenize)\n"
     ]
    }
   ],
   "source": [
    "print('\\nMost common words in tweets about Kamala Harris:')\n",
    "common_words(filtered_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common adjectives in tweets about Kamala Harris:\n",
      "american: 337\n",
      "many: 271\n",
      "new: 244\n",
      "illegal: 240\n",
      "good: 233\n",
      "last: 210\n",
      "conservative: 203\n",
      "bidenharris: 194\n",
      "amp: 180\n",
      "black: 173\n",
      "real: 164\n",
      "great: 163\n",
      "much: 161\n",
      "better: 157\n",
      "bad: 155\n",
      "free: 153\n",
      "political: 150\n",
      "white: 146\n",
      "first: 140\n",
      "old: 126\n",
      "big: 114\n",
      "presidential: 107\n",
      "open: 106\n",
      "sure: 106\n",
      "true: 99\n",
      "liberal: 99\n",
      "single: 99\n",
      "united: 99\n",
      "right: 99\n",
      "cant: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_18712\\2122204458.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['adjectives'] = df['text'].apply(clean_tokenize2)\n"
     ]
    }
   ],
   "source": [
    "print('\\nMost common adjectives in tweets about Kamala Harris:')\n",
    "common_adjectives(filtered_df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
